{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 1b: Training a SVM using QEK\n",
    "\n",
    "This tutorial demonstrates how to create a classification model using the QEK kernel with a generic database. By the end of this guide, you will know how to:\n",
    "\n",
    "1. **Define a Generic Graph Dataset**: Specify coordinates for the nodes in the dataset.\n",
    "2. **Compile a Register and Pulse from Each Graph**: Use these components that are used foe QPU execution.\n",
    "3. **Launch the Compiled Execution**: Run on either a quantum emulator or a physical QPU.\n",
    "    - 3.1. Execution on an emulator\n",
    "    - 3.2. Execution on Pasqals QPU\n",
    "4. **Extract QEK Features for Machine-Learning**: Utilize the results from the quantum execution to derive relevant features using the `QEK` Kernel.\n",
    "5. **Train a Machine Learning Model**: Build and train the model using the extracted features.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- A [companion notebook](./tutorial%20220-20Machine20Learning20with20QEK.ipynb) demonstrates advanced machine learning methods—including Grid Search—that can be used with the QEK kernel - using a real world molecular dataset.\n",
    "- If you prefer to work at a higher level without getting into quantum-level details, you might opt for the [high-level notebook](./tutorial%201%20-%20Using%20a%20Quantum%20Device%20to%20Extract%20Machine-Learning%20Features.ipynb), which abstracts these details using a more user-friendly API.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset Preparation\n",
    "\n",
    "As with any machine learning task, the first step is to load and prepare the data.\n",
    "\n",
    "### Overview\n",
    "QEK (Quantum-Enhanced Kernel) can work with various types of graphs. In this tutorial, we will use a generic synthetic graph dataset. The dataset will be generated using the `networkx` library, and we will incorporate features and target values to facilitate a classification task.\n",
    "\n",
    "### Steps\n",
    "\n",
    "- **Graph Generation**: We will create a synthetic graph using `networkx` and `torch_geometric` dataset.\n",
    "- **Assigning Node and Edge Features**: Each node and edge will be assigned relevant features.\n",
    "- **Target Value Assignment**: The target value for each graph will be based on its density. This value will be used in a classification task.\n",
    "- **Defining Graph Geometry**\n",
    "   - A generic grid-like geometry will be assigned.\n",
    "   - The positions of nodes will be stored in the `pos` variable.\n",
    "   - Users can define custom positions, ensuring compatibility with the QPU register.\n",
    "\n",
    "### Customization and Considerations\n",
    "- Users can modify the node and edge features as needed.\n",
    "- Custom graph layouts should be carefully designed to maintain compatibility with quantum processing unit (QPU)/mulator registers.\n",
    "\n",
    "By following these steps, we will prepare a dataset suitable for quantum-enhanced graph machine learning tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "\n",
    "class SyntheticGridGraphDataset(Dataset):\n",
    "    def __init__(self, num_graphs=100, nodes_list=[2, 4, 6, 10]):\n",
    "        \"\"\"\n",
    "        Creates a dataset of grid-like synthetic graphs with a controlled number of nodes.\n",
    "\n",
    "        Args:\n",
    "            num_graphs (int): Number of graphs to generate.\n",
    "            nodes_list (int): Number of nodes to be placed in the grid.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_graphs = num_graphs\n",
    "        self.nodes_list = nodes_list\n",
    "        self.graphs = []\n",
    "        for i in range(self.num_graphs):\n",
    "            for n in self.nodes_list:\n",
    "                self.graphs.append(self.create_graph(n))\n",
    "\n",
    "    def create_graph(self, num_nodes) -> Data:\n",
    "        \"\"\"Generates a structured grid graph where num_nodes dictate the grid size dynamically.\"\"\"\n",
    "        self.num_nodes = num_nodes\n",
    "        self.node_feat_dim = 2\n",
    "        self.edge_feat_dim = 2\n",
    "        # Determine grid size dynamically\n",
    "        rows = math.floor(math.sqrt(self.num_nodes))\n",
    "        cols = math.ceil(self.num_nodes / rows)\n",
    "\n",
    "        # Create a grid graph based on the exact number of nodes\n",
    "        G = nx.grid_2d_graph(rows, cols)\n",
    "        mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        # Retain only the first `num_nodes` nodes\n",
    "        select = self.num_nodes\n",
    "        selected_nodes = list(G.nodes())[:select]\n",
    "        subgraph = G.subgraph(selected_nodes)\n",
    "\n",
    "        # Get edges\n",
    "        edge_transpose = np.array(list(subgraph.edges)).T\n",
    "        if edge_transpose.size > 0:\n",
    "            edge_index = torch.tensor(edge_transpose, dtype=torch.long)\n",
    "        else:\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        # Generate structured 2D positions based on the dynamically computed grid\n",
    "        spacing = 5.0 \n",
    "        pos_array = np.array([[spacing * (i % cols), spacing * (i // cols)] for i in selected_nodes])\n",
    "        pos = torch.tensor(pos_array, dtype=torch.float)\n",
    "\n",
    "        # Node features (random)\n",
    "        node_features = torch.rand((select, self.node_feat_dim), dtype=torch.float)\n",
    "\n",
    "        # Edge attributes (random)\n",
    "        if edge_index.shape[1] > 0:\n",
    "            edge_attr = torch.rand((edge_index.shape[1], self.edge_feat_dim), dtype=torch.float)  \n",
    "        else:\n",
    "            edge_attr = torch.empty((0, self.edge_feat_dim), dtype=torch.float)\n",
    "\n",
    "        # Graph label (binary classification based on connectivity pattern)\n",
    "        label = torch.tensor([1 if np.random.rand() > 0.5 else 0], dtype=torch.long)\n",
    "\n",
    "        return Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, pos=pos, y=label)\n",
    "\n",
    "    def len(self):\n",
    "        return self.num_graphs * len(self.nodes_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.graphs[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with different number of nodes.\n",
    "dataset = SyntheticGridGraphDataset(num_graphs=100, nodes_list=[2, 3, 4, 5, 10, 15, 20])\n",
    "\n",
    "print(f\"\"\"Dataset created!\n",
    "      - Total Graphs: {len(dataset)}\n",
    "      - Sample Graph: {dataset[0]}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Notes on Geometry and Coordinates (`Pos`):*\n",
    "> This package lets researchers embed _graphs_ on Analog Quantum Devices. To do this we need to give these graphs a geometry (their positions in space) and to confirm that the geometry is compatible with a Quantum Device.\n",
    "\n",
    "> This package builds upon the [Pulser framework](https://pulser.readthedocs.io/). Our objective, in this notebook, is to _compile_ graphs\n",
    "into a format understood by our Quantum Devices. Which include, a _Pulser Register_ (the position of qubits) and _Pulser Pulses_ (the laser impulses controlling the evolution of the analog device).\n",
    "\n",
    "> As the geometry depends on the Quantum Device, we need to specify a device to use. For the time being, we'll use Pulser's `AnalogDevice`, which is\n",
    "a reasonable default device. We'll show you a bit further how to use another device.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the `BaseGraph` from qek_graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pulser as pl\n",
    "import qek.data.graphs as qek_graphs\n",
    "\n",
    "\n",
    "graphs_to_compile = []\n",
    "\n",
    "for i, data in enumerate(tqdm(dataset)):\n",
    "    graph = qek_graphs.BaseGraph(data=data, device=pl.AnalogDevice, id=i)\n",
    "    graph.target = data.y.item()\n",
    "    graphs_to_compile.append(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Compile a Register and a Pulse\n",
    "\n",
    "Once the embedding is found, we compile a Register (the position of atoms on the Quantum Device) and a Pulse (the lasers applied to these atoms).\n",
    "\n",
    "Note that not all graphs can be embedded on a given device. In this notebook, for the sake of simplicity, we simply discard graphs that cannot be trivially embedded. Future versions of this library may succeed at embedding more graphs.\n",
    "\n",
    "> The user can also define custom register and pulses using the  [Pulser framework](https://pulser.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qek.shared.error import CompilationError\n",
    "\n",
    "compiled = [] \n",
    "\n",
    "for graph in tqdm(graphs_to_compile):\n",
    "    try:\n",
    "        register = graph.compile_register()\n",
    "        pulse = graph.compile_pulse()\n",
    "    except CompilationError:\n",
    "        # Let's just skip graphs that cannot be computed.\n",
    "        print(\"Graph %s cannot be compiled for this device\" % (graph.id, ))\n",
    "        continue\n",
    "    compiled.append((graph, register, pulse))\n",
    "print(\"Compiled %s graphs into registers/pulses\" % (len(compiled, )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of these registers and pulses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_graph, example_register, example_pulse = compiled[53]\n",
    "example_register.draw(blockade_radius=pl.AnalogDevice.min_atom_distance + 0.01)\n",
    "example_pulse.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Execution\n",
    "\n",
    "In this section we will showcase how to execute from register and pulses. This execution will lead to a processed dataset, that we can eventually use to create the QEK Kernel. \n",
    "- The results of executing the embedding on the Quantum Device are in field `state_dict`.\n",
    "- `state_dict` will be used in the `QEK` Kernel in the next steps.\n",
    "\n",
    "### 3.1) Executing on an emulator\n",
    "\n",
    "While our objective is to run on a physical QPU, it is generally a good idea to test on an emulator first. For this example, we'll use the QutipEmulator, the simplest emulator provided with Pulser.\n",
    "\n",
    "> Pasqal has also developed an emulator called emu-mps, which generally provides much better performance and resource usage, so if you hit resource limits, don't hesitate to [check it out](https://github.com/pasqal-io/emulators)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qek.data.processed_data import ProcessedData\n",
    "from qek.backends import QutipBackend\n",
    "\n",
    "# In this tutorial, to make things faster, we'll only run 5 qubits or less.\n",
    "# If you wish to run more entries, feel free to increase this value.\n",
    "#\n",
    "# # Warning\n",
    "#\n",
    "# Emulating a Quantum Device takes exponential amount of resources and time! If you set MAX_QUBITS too\n",
    "# high, you can bring your computer to its knees and/or crash this notebook.\n",
    "MAX_QUBITS = 5\n",
    "\n",
    "processed_dataset = []\n",
    "executor = QutipBackend(device=pl.AnalogDevice)\n",
    "for graph, register, pulse in tqdm(compiled):\n",
    "    if len(register.qubits) > MAX_QUBITS:\n",
    "        continue\n",
    "    states = await executor.run(register=register, pulse=pulse)\n",
    "    processed_dataset.append(ProcessedData.from_register(register=register, pulse=pulse, device=pl.AnalogDevice, state_dict=states, target=graph.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Executing on a QPU\n",
    "\n",
    "Once you have checked that the pulses work on an emulator, you will probably want to move to a QPU. Execution on a QPU takes\n",
    "resources polynomial in the number of qubits, which hopefully means an almost exponential speedup for large number of qubits.\n",
    "\n",
    "To experiment with a QPU, you will need either physical access to a QPU, or an account with [PASQAL Cloud](https://docs.pasqal.cloud), which provides you remote access to QPUs built and hosted by Pasqal. In this section, we'll see how to use the latter.\n",
    "\n",
    "If you don't have an account, just skip to the next section!\n",
    "\n",
    "> There are other ways to use the SDK. For instance, you can enqueue a job and check later whether it has completed. Also, to work around the long waiting lines, Pasqal provides high-performance distributed and hardware-accelerated emulators, which you can access through the SDK. For more details, [take a look at the documentation of the SDK](https://docs.pasqal.cloud/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAVE_PASQAL_ACCOUNT = False # If you have a PASQAL Cloud account, fill in the details and set this to `True`.\n",
    "\n",
    "if HAVE_PASQAL_ACCOUNT: \n",
    "    from qek.backends import RemoteQPUBackend\n",
    "    processed_dataset = []\n",
    "\n",
    "    # Initialize connection\n",
    "\n",
    "    my_project_id = \"your_project_id\"# Replace this value with your project_id on the PASQAL platform.\n",
    "    my_username   = \"your_username\"  # Replace this value with your username or email on the PASQAL platform.\n",
    "    my_password   = \"your_password\"  # Replace this value with your password on the PASQAL platform.\n",
    "        # Security note: In real life, you probably don't want to write your password in the code.\n",
    "        # See the documentation of PASQAL Cloud for other ways to provide your password.\n",
    "\n",
    "    # Initialize the cloud client\n",
    "    executor = RemoteQPUBackend(username=my_username, project_id=my_project_id, password=my_password)\n",
    "\n",
    "    # Fetch the specification of our QPU\n",
    "    device = await executor.device()\n",
    "\n",
    "    # As previously, create the list of graphs and embed them.\n",
    "    graphs_to_compile = []\n",
    "    for i, data in enumerate(tqdm(dataset)):\n",
    "        graph = qek_graphs.PTCFMGraph(data=data, device=device, id=i)\n",
    "        graphs_to_compile.append(graph)\n",
    "\n",
    "    compiled = []\n",
    "    for graph in tqdm(graphs_to_compile):\n",
    "        try:\n",
    "            register = graph.compile_register()\n",
    "            pulse = graph.compile_pulse()\n",
    "        except CompilationError:\n",
    "            # Let's just skip graphs that cannot be computed.\n",
    "            print(\"Graph %s cannot be compiled for this device\" % (graph.id, ))\n",
    "            continue\n",
    "    compiled.append((graph, register, pulse))\n",
    "\n",
    "    # Now that the connection is initialized, we just have to send the work\n",
    "    # to the QPU and wait for the results.\n",
    "    for graph, register, pulse in tqdm(compiled):\n",
    "\n",
    "        # Send the work to the QPU and await the result\n",
    "        states = await executor.run(register=register, pulse=pulse)\n",
    "        processed_dataset.append(ProcessedData.from_register(register=register, pulse=pulse, device=device, state_dict=states, target=graph.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one of our samples:\n",
    "\n",
    "#### *State Dict*\n",
    "\n",
    "> This dictionary represents an approximation of the quantum state of the device for this graph after completion of the algorithm.\n",
    "> - each of the keys represents one possible state for the register (which represents the graph), with each qubit (which represents a single node) being in state `0` or `1`;\n",
    "> - the corresponding value is the number of samples observed with this specific state of the register.\n",
    "\n",
    "> Note: Since Quantum Devices are inherently non-deterministic, you will probably obtained different samples if you run this on a Quantum Device instead of loading the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_example: ProcessedData = processed_dataset[53]\n",
    "print(f\"\"\"Total number of samples: {len(processed_dataset)}\n",
    "        - Example state_dict {dataset_example.state_dict}\"\"\")\n",
    "dataset_example.draw_register()\n",
    "dataset_example.draw_pulse()\n",
    "display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4). Extract QEK Features for Machine-Learning\n",
    "\n",
    "What we have seen so far covers the use of a Quantum Device to extract features. Now we will utilize the execution result to create the QEK Kernel.\n",
    "\n",
    "### Introduction\n",
    "This tutorial uses scikit-learn for common machine learning tasks, but the concepts would work with any other machine learning framework as well.\n",
    "- First we will split the dataset into train and test datasets\n",
    "- Secondly, we will initialize and `fit` the QEK Kernel.\n",
    "\n",
    "From the state dictionary, we derive as machine-learning feature the _distribution of excitation_. We'll use this in the next parts to define our kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features (X) and targets (y)\n",
    "X = [data for data in processed_dataset]  \n",
    "y = [data.target for data in processed_dataset] \n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=42)\n",
    "print(f'Size of the training quantum compatible dataset = {len(X_train)}')\n",
    "print(f'Size of the testing quantum compatible dataset = {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[53].draw_excitation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Quantum Evolution Kernel computes a similarity score between two graphs based on quantum-inspired measures. It is designed to work with graph-structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qek.kernel import QuantumEvolutionKernel as QEK\n",
    "\n",
    "# Initialize the Quantum Evolution Kernel with a parameter mu\n",
    "kernel = QEK(mu=0.5)\n",
    "\n",
    "# Fit\n",
    "kernel.fit(X_train)\n",
    "\n",
    "# Transform\n",
    "K_train = kernel.transform(X_train)\n",
    "K_test = kernel.transform(X_test)\n",
    "\n",
    "print(f\"Training Kernel Matrix Shape: {K_train.shape}\")\n",
    "print(f\"Testing Kernel Matrix Shape: {K_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Train a Machine Learning Model\n",
    "\n",
    "We will use an SVM (Support Vector Machine) to learn how to predict the toxicity of a molecule based on the precomputed kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define a SVC model with QuantumEvolutionKernel\n",
    "qek_kernel = QEK(mu=0.5)\n",
    "model = SVC(kernel=qek_kernel, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "This precomputed kernel will allow us to evaluate the algorithm QEK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the trained model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the trained model and test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.2f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this was a synthetic dataset with random features, the accuracy is low. The model can also be tuned further, For extra details on a real dataset, please see the  [companion notebook](./tutorial%201%20-%20Using%20a%20Quantum%20Device%20to%20Extract%20Machine-Learning%20Features.ipynb) for advanced ML steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum-evolution-kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
