{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QEK from A to Z\n",
    "\n",
    "This notebook reproduces the results of the [QEK paper](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.107.042615).\n",
    "\n",
    "At the end, you will be able to:\n",
    "1. Extract the embeddings of a molecular dataset\n",
    "2. Compile these embeddings into Pulse sequences for use on a Quantum Device or an amulator.\n",
    "3. Run the Pulse sequences on a Quantum Device or an emulator.\n",
    "4. Train an SVM with the QEK (Quantum Evolution Kernel) kernel and benchmark the performance reported in the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch_geometric.datasets as pyg_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "\n",
    "As in any machine learning task, we first need to load and prepare data. QEK can work with many types of graphs, including molecular graphs. For this tutorial, we will use the PTC-FM dataset, which contains such molecular graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original PTC-FM dataset\n",
    "og_ptcfm = [data for data in pyg_dataset.TUDataset(root=\"dataset\", name=\"PTC_FM\")]\n",
    "\n",
    "display(\"Loaded %s samples\" % (len(og_ptcfm), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract machine-learning features from our dataset, we will need to configure a feature extractor. This library provides several feature extractors to either make use of a physical quantum device (QPU), or a variety of emulators.\n",
    "\n",
    "To configure a feature extractor, we will need to give it a _compiler_, whose task is to take a list of graphs, extract embeddings and compile these embeddings to _sequences of pulses_, the format that can be executed  by either a QPU or an emulator. For this tutorial, our dataset is composed of molecule graphs, so we will use the `MoleculeGraphCompiler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qek.data.graphs as qek_graphs\n",
    "\n",
    "compiler = qek_graphs.MoleculeGraphCompiler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library provides other compilers from other formats of graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and executing a feature extractor from an emulator\n",
    "\n",
    "The easiest way to process a graph is to compile and execute it for an emulator. QEK is built on top of Pulser, which provides several emulators. The simplest of these emulators is the `QutipEmulator`, which QEK uses for the `QutipExtractor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qek.data.extractors as qek_extractors\n",
    "\n",
    "# Use the Qutip Extractor.\n",
    "extractor = qek_extractors.QutipExtractor(\n",
    "    # Once computing is complete, data will be saved in this file.\n",
    "    path=\"saved_data.json\",\n",
    "    compiler=compiler\n",
    ")\n",
    "\n",
    "# Add the graphs using the compiler we've picked previously.\n",
    "extractor.add_graphs(graphs=og_ptcfm)\n",
    "\n",
    "# We may now compile them.\n",
    "compiled = extractor.compile()\n",
    "display(\"Compiled %s sequences\" % (len(compiled), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the number of sequences compiled is lower than the number of samples loaded. Some of this is due to limitations within the algorithm (not all graphs can be efficiently laid out for execution on a Quantum Device), while others are due to the limitations of the emulator we target (which at the time of this writing is limited to 50 qubits).\n",
    "\n",
    "We may now run the extraction on the emulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of qubits for this run, for performance reasons.\n",
    "# You can increase this value to higher number of qubits, but this\n",
    "# notebook will take longer to execute and may run out of memory.\n",
    "max_qubits = 5\n",
    "processed_dataset = await extractor.run(max_qubits=max_qubits) # Don't forget to `await`!\n",
    "display(\"Extracted features from %s samples\"% (len(processed_dataset), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to extract features from more samples, feel free to increase the value of `max_qubits` above. However, you will soon run into limitations of a quantum emulator, and possibly crash this notebook. At this point, you have other options, such as using `EmuMPSExtractor` instead of `QutipExtractor`, a more recent emulator that features much better performance in most cases, or you can run the extraction on a physical QPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and executing a feature extractor on a physical QPU\n",
    "\n",
    "Once you have checked that low qubit sequences provide the results you expect on an emulator, you will generally want to move to a QPU.\n",
    "For this, you will need either physical access to a QPU, or an account with [PASQAL Cloud](https://docs.pasqal.cloud), which provides\n",
    "you remote access to QPUs built and hosted by Pasqal. In this section, we'll see how to use the latter.\n",
    "\n",
    "If you don't have an account, just skip to the next section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAVE_PASQAL_ACCOUNT = False # If you have a PASQAL Cloud account, fill in the details and set this to `True`.\n",
    "\n",
    "if HAVE_PASQAL_ACCOUNT:\n",
    "    processed_dataset = []\n",
    "\n",
    "    # Use the QPU Extractor.\n",
    "    extractor = qek_extractors.QPUExtractor(\n",
    "        # Once computing is complete, data will be saved in this file.\n",
    "        path=\"saved_data.json\",\n",
    "        compiler = compiler,\n",
    "        project_id = \"XXXX\", # Replace this with your project id on the PASQAL Cloud\n",
    "        username = \"XXX\",    # Replace this with your username on PASQAL Cloud\n",
    "        password = None,     # Replace this with your password on PASQAL Cloud or enter it on the command-line\n",
    "    )\n",
    "\n",
    "    # Add the graphs, exactly as above.\n",
    "    extractor.add_graphs(graphs=og_ptcfm)\n",
    "\n",
    "    # We may now compile, exactly as above.\n",
    "    compiled = extractor.compile()\n",
    "    display(\"Compiled %s sequences\" % (len(compiled), ))\n",
    "\n",
    "    # Launch the execution.\n",
    "    execution = extractor.run()\n",
    "    display(\"Work enqueued with ids %s\" % (extractor.batch_ids, ))\n",
    "\n",
    "    # ...and wait for the results.\n",
    "    processed_dataset = await execution\n",
    "    display(\"Extracted features from %s samples\"% (len(processed_dataset), ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the process is essentially identical to executing with an emulator. Note that, as of this\n",
    "writing, the waiting line to access a QPU can be very long (typically several hours).\n",
    "\n",
    "There are two main ways to deal with this:\n",
    "\n",
    "1. `QPUExtractor` can be attached to an ongoing job from batch ids, so that you can resume your work\n",
    "    e.g. after turning off your computer.\n",
    "2. Pasqal CLOUD offers access to high-performance hardware-based emulators, with dramatically\n",
    "    shorter waiting lines.\n",
    "\n",
    "See [the documentation](https://pqs.pages.pasqal.com/quantum-evolution-kernel/) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...or using the provided dataset\n",
    "\n",
    "For this notebook, instead of spending hours running the simulator on your computer, we're going to skip\n",
    "this step and load on we're going to cheat and load the results, which are conveniently stored in `ptcfm_processed_dataset.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qek.data.dataset as qek_dataset\n",
    "processed_dataset = qek_dataset.load_dataset(file_path=\"ptcfm_processed_dataset.json\")\n",
    "print(f\"Size of the quantum compatible dataset = {len(processed_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the sequence for one of the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_example = processed_dataset[64]\n",
    "dataset_example.draw_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_example.draw_register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of executing the embedding on the Quantum Device are in field `state_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_example.state_dict)\n",
    "print(f\"Total number of samples: {sum(dataset_example.state_dict.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary represents an approximation of the quantum state of the device for this graph after completion of the algorithm.\n",
    "\n",
    "- each of the keys represents one possible state for the register (which represents the graph), with each qubit (which represents a single node) being in state `0` or `1`;\n",
    "- the corresponding value is the number of samples observed with this specific state of the register.\n",
    "\n",
    "In this example, for instance, we can see that the state observed most frequently is `10000001010`, with 43/1000 samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning-features\n",
    "\n",
    "From the state dictionary, we derive as machine-learning feature the _distribution of excitation_. We'll use this in a second to define our kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_example.draw_excitation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your first quantum machine learning algorithm\n",
    "\n",
    "The next step is to use the results of the Quantum Device execution on a classical device (i.e. your computer) to create a Quantum Evolution Kernel. Since our algorithm combines steps that are executed on a Quantum Device and steps that are executed on a classical device, we call this a _hybrid algorithm_.\n",
    "\n",
    "## Introducing the Quantum Evolution Kernel\n",
    "\n",
    "For a graph $G$, let's call the excitation distribution $P_G$.\n",
    "\n",
    "We may now construct the Quantum Evolution Kernel, or QEK. Mathematically, QEK defined as:\n",
    "$$\n",
    "K(G, G') = \\exp \\left( -\\mu JS(P_G, P_{G'}) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\mu$ is an hyperparameter of our kernel and $JS$ is the Jensen-Shannon distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qek.kernel import QuantumEvolutionKernel as QEK\n",
    "kernel = QEK(mu=2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter $\\mu$ controls the rate of exponential decay. A large value of $\\mu$ makes QEK very sensitive to small variations of the Jensen-Shanon distance. Conversely, when $\\mu$ is small, the kernel is less affected by small variations in of $JS$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QEK compares two processed graphs by their distribution of excitations. If `a` and `b` are two graphs, a value of `kernel(a, b)` close to 1 indicates a big similarity between graphs `a` and `b`, while a value close to 0 means a small graph similarity.\n",
    "\n",
    "Let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_1 = processed_dataset[2]\n",
    "graph_1.draw_register()\n",
    "graph_1.draw_excitation()\n",
    "display(f\"Comparing a graph with itself: {kernel(graph_1=graph_1, graph_2=graph_1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_2 = processed_dataset[0]\n",
    "graph_2.draw_register()\n",
    "graph_2.draw_excitation()\n",
    "display(f\"Comparing two much non similar graphs: {kernel(graph_1=graph_1, graph_2=graph_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will calculate the kernel on the entire dataset of PTC-FM. We obtain an NxN matrix (where N is the number of graphs in the dataset). This matrix contains the similarities two by two of the graphs.\n",
    "\n",
    "This precomputed kernel will allow us to evaluate the algorithm QEK. We will use an SVM (Support Vector Machine) to learn how to predict the toxicity of a molecule based on the precomputed kernel. This task is handled with the `train_and_evaluate_ml_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kernel = kernel.create_train_kernel_matrix(processed_dataset)\n",
    "y_tot = [data.target for data in processed_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MLResults:\n",
    "    \"\"\"\n",
    "    Stores the results of a machine learning model evaluation.\n",
    "    \n",
    "    This class provides attributes to store the mean and standard deviation of F1 score \n",
    "    and balanced accuracy, which are common metrics used in classification problems.\n",
    "\n",
    "    Attributes:\n",
    "        f1_score (float): Mean F1 score of the model.\n",
    "        std_f1_score (float): Standard deviation of F1 scores across different folds.\n",
    "        balanced_acc (float): Mean balanced accuracy of the model.\n",
    "        std_balanced_acc (float): Standard deviation of balanced accuracies across different folds.\n",
    "    \"\"\"\n",
    "    f1_score: float\n",
    "    std_f1_score: float\n",
    "    balanced_acc: float\n",
    "    std_balanced_acc: float\n",
    "\n",
    "\n",
    "def train_and_evaluate_ml_model(K: np.ndarray, targets: list[int], seed1: int|None = None,\n",
    "                                seed2: int|None = None):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a Support Vector Machine (SVM) model on the provided kernel.\n",
    "\n",
    "    It employs a stratified k-fold cross-validation strategy with repeated splits\n",
    "    to ensure robustness and reliability of the results.\n",
    "\n",
    "    Parameters:\n",
    "        K (np.ndarray): The precomputed kernel matrix.\n",
    "        targets (list[int]): A list of target values for the training data.\n",
    "        seed1 (int, optional): The random state used for stratified k-fold cross-validation.\n",
    "            Defaults to None.\n",
    "        seed2 (int, optional): The random state used for the SVM estimator. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        MLResults: An instance containing the mean and standard deviation of F1 score and\n",
    "            balanced accuracy.\n",
    "    \"\"\"\n",
    "    C_list = np.linspace(0.001, 100, 100)\n",
    "    param_grid = {\"C\": C_list}\n",
    "    scoring = {\"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
    "                \"f1_score\": make_scorer(f1_score, average=\"weighted\")\n",
    "                }\n",
    "\n",
    "    skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=seed1)\n",
    "\n",
    "\n",
    "    estimator = svm.SVC(kernel=\"precomputed\", random_state=seed2)\n",
    "    grid_search = GridSearchCV(estimator, param_grid, scoring=scoring,\n",
    "                                    cv=skf, refit=False, n_jobs=8)\n",
    "    \n",
    "\n",
    "    result = grid_search.fit(K, targets).cv_results_\n",
    "    max_f1_score = np.mean(result[\"mean_test_f1_score\"]) \n",
    "    final_f1_std = np.mean(result[\"std_test_f1_score\"])\n",
    "    max_bal_acc = np.mean(result[\"mean_test_balanced_accuracy\"]) \n",
    "    std_bal_acc = np.mean(result[\"std_test_balanced_accuracy\"])\n",
    "    final_score = MLResults(f1_score=max_f1_score, std_f1_score=final_f1_std,\n",
    "                            balanced_acc=max_bal_acc, std_balanced_acc=std_bal_acc)\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_and_evaluate_ml_model(K=train_kernel, targets=y_tot, seed1=42, seed2=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We are using two metrics:\n",
    "- The F1 score is a way to measure how well a model performs, especially when the data is uneven (e.g., more examples of one category than another). It combines two important aspects: how precise the model is (how many of the predicted positives are actually positive) and how well it captures all the actual positives (recall). It provides a single number that balances these two aspects, making it useful for evaluating performance in real-world scenarios where some categories are much more common than others.\n",
    "\n",
    "- Balanced accuracy is a method to evaluate a model's performance fairly, even when the data is imbalanced (e.g., one category is much more frequent than others). Instead of just looking at overall accuracy, which can be misleading in such cases, balanced accuracy considers how well the model performs for each category separately and then averages these performances. This ensures that the evaluation is not skewed by the more common categories, giving a more honest picture of the model's effectiveness across all categories.\n",
    "\n",
    "\n",
    "Inside the `train_and_evaluate_ml_model`function, we split our data multiple times to ensure each fold is representative of the overall class distribution, helping to mitigate bias. The mean value and standard deviation (std) of each metrics from this process provide an average performance measure and the variability of that performance across different data splits, giving you a robust understanding of your model's consistency and reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean F1 score = {results.f1_score}\")\n",
    "print(f\"Standard deviation of F1 score = {results.std_f1_score}\")\n",
    "print(f\"Mean balanced accuracy {results.balanced_acc}\")\n",
    "print(f\"Standard deviation of balanced accuracy {results.std_balanced_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum-evolution-kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
