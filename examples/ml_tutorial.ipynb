{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80370a5d",
   "metadata": {},
   "source": [
    "# Quantum Evolution Kernel-Based Machine Learning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf947b9",
   "metadata": {},
   "source": [
    "\n",
    "### Introduction\n",
    "Machine Learning (ML) is a field of artificial intelligence that focuses on building systems capable of learning from data to make predictions or decisions. A common ML task is classification, where we try to assign labels to data points. In this tutorial, we will use the **Quantum Evolution Kernel**, a custom kernel that computes the similarity between graph-structured data to model a classification problem using Support Vector Machine (SVM) on graph dataset.\n",
    "\n",
    "\n",
    "\n",
    "### Tutorial Objectives\n",
    "This tutorial will guide you through:\n",
    "1. Loading and preprocessing a dataset for kernel-based machine learning.\n",
    "2. Introduction to **Quantum Evolution Kernel** (QEK), including *fit* and *transform* methods.\n",
    "3. Training and evaluating a **Support Vector Machine** (SVM) using the Quantum Evolution Kernel.\n",
    "4. Integrating the kernel and SVM into a scikit-learn **Pipeline** for streamlined workflows.\n",
    "5. Performing hyperparameter optimization using **GridSearchCV** to improve model performance.\n",
    "\n",
    "In this tutorial, we use the results of the Quantum Device execution on a classical device (i.e. your computer) to create a Quantum Evolution Kernel. Since our algorithm combines steps that are executed on a Quantum Device and steps that are executed on a classical device, we call this a _hybrid algorithm_.\n",
    "\n",
    "This tutorial uses scikit-learn for common machine learning tasks, but the concepts would work with any other machine learning framework as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474d400",
   "metadata": {},
   "source": [
    "## 1. Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e294f5",
   "metadata": {},
   "source": [
    "We begin by loading a dataset that contains graph-structured data. Each data point is represented as a processed object with features and a target value. We will split the data into training and testing sets for model evaluation.\n",
    "\n",
    "- Each processed data point has a _state_dict_: This dictionary represents an approximation of the quantum state of the device for this graph after completion of the algorithm. From the state dictionary, we derive as machine-learning feature the _distribution of excitation_. We'll use these in the next step to define our kernel.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9cd6d6-1c44-476b-9bd2-86fd8048eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qek.data.dataset as qek_dataset\n",
    "\n",
    "# Load the dataset we processed in the quantum extraction tutorial\n",
    "processed_dataset = qek_dataset.load_dataset(file_path=\"ptcfm_processed_dataset.json\")\n",
    "print(f\"Size of the quantum compatible dataset = {len(processed_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ecc8a9-ecab-4799-8cb8-b63fac9f8d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features (X) and targets (y)\n",
    "X = [data for data in processed_dataset]  \n",
    "y = [data.target for data in processed_dataset] \n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb6b56-3c77-48da-a3ac-50c55604e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Size of the training quantum compatible dataset = {len(X_train)}')\n",
    "print(f'Size of the testing quantum compatible dataset = {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413bebc-b378-431f-9363-2b7729a15770",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_example = X[64]\n",
    "# The features we have extracted for this sample\n",
    "dataset_example.draw_excitation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b2fc2a",
   "metadata": {},
   "source": [
    "## 2. Quantum Evolution Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9e2dd",
   "metadata": {},
   "source": [
    "The Quantum Evolution Kernel computes a similarity score between two graphs based on quantum-inspired measures. It is designed to work with graph-structured data.\n",
    "\n",
    "- *A **kernel** is a function that computes a similarity measure between two data points. In ML, kernels are often used to implicitly map data into a higher-dimensional space without computing the transformation explicitly. This enables algorithms like Support Vector Machines (SVM) to solve problems that are not linearly separable in the original feature space.*\n",
    "\n",
    "\n",
    "### Introducing the Quantum Evolution Kernel\n",
    "\n",
    "For a graph $G$, let's call the excitation distribution $P_G$.\n",
    "\n",
    "We may now construct the Quantum Evolution Kernel, or QEK. Mathematically, QEK is defined as:\n",
    "$$\n",
    "K(G, G') = \\exp \\left( -\\mu JS(P_G, P_{G'}) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\mu$ is an hyperparameter of our kernel and $JS$ is the Jensen-Shannon divergence.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f264f6-18f5-4009-930a-12cce4a2cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qek.kernel import QuantumEvolutionKernel as QEK\n",
    "\n",
    "# Initialize the Quantum Evolution Kernel with a parameter mu\n",
    "kernel = QEK(mu=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea18c5",
   "metadata": {},
   "source": [
    "### `Fit` and `Transform` graph datasets using `QEK`\n",
    "\n",
    "To use the kernel in machine learning algorithms, we can fit the kernel on a training dataset, and use it to transform training/testing datasets. The result of such a transformation is a kernel matrix, which represents the similarities between graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfaa8e-b0c7-4020-90f5-86e2db4adf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "kernel.fit(X_train)\n",
    "\n",
    "# Transform\n",
    "K_train = kernel.transform(X_train)\n",
    "K_test = kernel.transform(X_test)\n",
    "\n",
    "print(f\"Training Kernel Matrix Shape: {K_train.shape}\")\n",
    "print(f\"Testing Kernel Matrix Shape: {K_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f269e-a63b-4769-b5fa-d12a3972271b",
   "metadata": {},
   "source": [
    "The kernel matrix for the testing dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e24ca5-593a-4d92-8537-7e1b61000745",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c9979",
   "metadata": {},
   "source": [
    "Parameter $\\mu$ controls the rate of exponential decay. A large value of $\\mu$ makes QEK very sensitive to small variations of the Jensen-Shanon distance. Conversely, when $\\mu$ is small, the kernel is less affected by small variations in of $JS$.\n",
    "\n",
    "\n",
    "QEK compares two processed graphs by their distribution of excitations. If `a` and `b` are two graphs, a value of `kernel(a, b)` close to 1 indicates a big similarity between graphs `a` and `b`, while a value close to 0 means a small graph similarity.\n",
    "\n",
    "Let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_1 = processed_dataset[2]\n",
    "graph_2 = processed_dataset[0]\n",
    "\n",
    "display(f\"Comparing a graph with itself: {kernel.similarity(graph_1, graph_1)}\")\n",
    "display(f\"Comparing two much dissimilar graphs: {kernel.similarity(graph_1, graph_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1362ca",
   "metadata": {},
   "source": [
    "We can further validate this by checking that the two graphs are registered differently and have different excitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_1.draw_register()\n",
    "graph_2.draw_register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_1.draw_excitation()\n",
    "graph_2.draw_excitation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8beac46-beb0-445b-add2-39c531b3dae5",
   "metadata": {},
   "source": [
    "## 3. Training a simple model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f49a8",
   "metadata": {},
   "source": [
    "We will use an SVM (Support Vector Machine) to learn how to predict the toxicity of a molecule based on the precomputed kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc7d4b-b8c9-440e-ae6f-4a59d99e4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from qek.kernel import QuantumEvolutionKernel as QEK\n",
    "\n",
    "# Define a SVC model with QuantumEvolutionKernel\n",
    "qek_kernel = QEK(mu=0.5)\n",
    "model = SVC(kernel=qek_kernel, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd1cf0",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "This precomputed kernel will allow us to evaluate the algorithm QEK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c47cc-d6e4-423f-a3bc-72dcbf38e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9b23b",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "\n",
    "We are using the following metrics:\n",
    "- The F1 score is a way to measure how well a model performs, especially when the data is uneven (e.g., more examples of one category than another). It combines two important aspects: how precise the model is (precision) and how well it captures all the actual positives (recall). It provides a single number that balances these two aspects, making it useful for evaluating performance in real-world scenarios where some categories are much more common than others.\n",
    "\n",
    "- Balanced accuracy is a method to evaluate a model's performance fairly, even when the data is imbalanced (e.g., one category is much more frequent than others). Instead of just looking at overall accuracy, which can be misleading in such cases, balanced accuracy considers how well the model performs for each category separately and then averages these performances. This ensures that the evaluation is not skewed by the more common categories, giving a more honest picture of the model's effectiveness across all categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e35d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_predictions(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluates the model predictions using multiple metrics: F1 score, and\n",
    "    balanced accuracy. Prints the classification report \n",
    "    and other evaluation results.\n",
    "\n",
    "    Args:\n",
    "        y_test (array-like): The true labels.\n",
    "        y_pred (array-like): The predicted labels.\n",
    "    \"\"\"\n",
    "    # Calculate F1 score and balanced accuracy\n",
    "    max_f1_score = f1_score(y_test, y_pred, average='weighted')\n",
    "    final_f1_std = np.std(f1_score(y_test, y_pred, average=None))\n",
    "    max_bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    std_bal_acc = np.std(balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Print the evaluation results\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    print(f\"F1 Score: {max_f1_score:.2f}\")\n",
    "    print(f\"Standard Deviation of F1 Score: {final_f1_std:.2f}\")\n",
    "    print(f\"Balanced Accuracy: {max_bal_acc:.2f}\")\n",
    "    print(f\"Standard Deviation of Balanced Accuracy: {std_bal_acc:.2f}\")\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2715f09",
   "metadata": {},
   "source": [
    "We can use the trained model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ef4e5-312f-4b77-82c3-6714967d6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "evaluate_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace7744",
   "metadata": {},
   "source": [
    "## 4. Creating a Pipeline with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7b90f",
   "metadata": {},
   "source": [
    "Pipelines in scikit-learn allow us to streamline the workflow by chaining preprocessing steps and models. In this step, we integrate the Quantum Evolution Kernel with an SVM classifier in a pipeline for end-to-end model training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f685005-037c-406c-82ef-dfce71701eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from qek.kernel import QuantumEvolutionKernel as QEK\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('QEK', QEK(mu=0.5)),\n",
    "    ('svm', SVC(kernel='precomputed', random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e587d4-790e-4cfa-99ac-a8b3f4271094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b1165-758a-477c-919a-9d694acc6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the trained model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "evaluate_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b994cf",
   "metadata": {},
   "source": [
    "## 5. GridSearchCV for Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022d7fd",
   "metadata": {},
   "source": [
    "\n",
    "Hyperparameter tuning is a critical step in improving machine learning model performance. **GridSearchCV** systematically searches through a predefined set of hyperparameters to find the combination that yields the best results. Here, we optimize:\n",
    "\n",
    "- `mu`: A parameter of the Quantum Evolution Kernel.\n",
    "- `C`: The regularization parameter of the SVM.\n",
    "\n",
    "We will use the pipeline defined in the previous section inside the grid search. Additionally, we employ multiple scoring metrics such as F1 Score and Balanced Accuracy to evaluate the performance of the models comprehensively.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc3e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    \"balanced_accuracy\": make_scorer(balanced_accuracy_score),\n",
    "    \"f1_score\": make_scorer(f1_score, average=\"weighted\")\n",
    "}\n",
    "\n",
    "# Define cross-validation strategy\n",
    "skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'svm__C': np.logspace(0.001, 1, 5),\n",
    "    'QEK__mu': [0.25, 0.5, 0.75],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring=scoring, cv=skf, refit=\"f1_score\", n_jobs=8, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13e7af",
   "metadata": {},
   "source": [
    "### Evaluation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7939ae2c",
   "metadata": {},
   "source": [
    "We can access best trained model from the grid search using *.best_estimator_*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325f8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "evaluate_predictions(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b02853",
   "metadata": {},
   "source": [
    "We can also access the results of grid search using *.cv_results_*. This allows us to plot learning curves, as well as see the impact of different hyperparamters on model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7965571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results\n",
    "cv_results = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple plot function to plot results\n",
    "import numpy as np\n",
    "\n",
    "def plot_grid_search_results(grid_search, param_name=\"svm__C\"):\n",
    "    cv_results = grid_search.cv_results_\n",
    "    param_values = [p[param_name] for p in cv_results['params']]\n",
    "    unique_param_values = sorted(set(param_values))\n",
    "\n",
    "    mean_f1_scores = []\n",
    "    std_f1_scores = []\n",
    "\n",
    "    for param_value in unique_param_values:\n",
    "        indices = [i for i, p in enumerate(cv_results['params']) if p[param_name] == param_value]\n",
    "        mean_f1_scores.append(np.mean([cv_results['mean_test_f1_score'][i] for i in indices]))\n",
    "        std_f1_scores.append(np.mean([cv_results['std_test_f1_score'][i] for i in indices]))\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(unique_param_values, mean_f1_scores, label=\"Mean F1 Score\")\n",
    "    plt.fill_between(unique_param_values, \n",
    "                     np.array(mean_f1_scores) - np.array(std_f1_scores),\n",
    "                     np.array(mean_f1_scores) + np.array(std_f1_scores), \n",
    "                     alpha=0.2)\n",
    "    \n",
    "    plt.title(f\"Grid Search Results for {param_name}\")\n",
    "    plt.xlabel(f\"{param_name}\")\n",
    "    plt.ylabel(\"Mean F1 Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a06e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search_results(grid_search, 'svm__C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ced10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid_search_results(grid_search, 'QEK__mu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QEKENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
